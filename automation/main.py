#!/usr/bin/env python3
"""
ResLibs ç™¾åº¦ç½‘ç›˜è‡ªåŠ¨åŒ–è„šæœ¬ä¸»æ¡†æ¶
å®ç°å®Œæ•´çš„èµ„æºè‡ªåŠ¨åŒ–å¤„ç†æµç¨‹
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from automation.config import config
from automation.logger import setup_logger
from automation.simple_database import SimpleDatabaseManager as DatabaseManager
from automation.baidu_client import BaiduPanClient
from automation.content_generator import ContentGenerator
from automation.image_manager import ImageManager
from automation.cloudflare_r2 import CloudflareR2Manager
from automation.hosting_manager import HostingManager


@dataclass
class ResourceInfo:
    """èµ„æºä¿¡æ¯"""
    path: str
    filename: str
    size: int
    modified_time: datetime
    file_type: str
    resource_type: str
    download_url: Optional[str] = None
    local_path: Optional[str] = None
    content_data: Optional[Dict[str, Any]] = None
    images: List[str] = None
    hosting_links: List[Dict[str, str]] = None

    def __post_init__(self):
        if self.images is None:
            self.images = []
        if self.hosting_links is None:
            self.hosting_links = []


class ResourceProcessor:
    """èµ„æºå¤„ç†å™¨"""

    def __init__(self):
        self.logger = setup_logger("ResourceProcessor")
        self.db = DatabaseManager()
        self.baidu_client = BaiduPanClient()
        self.content_generator = ContentGenerator()
        self.image_manager = ImageManager()
        self.r2_manager = CloudflareR2Manager()
        self.hosting_manager = HostingManager()

    async def process_single_resource(self, resource_info: ResourceInfo) -> bool:
        """å¤„ç†å•ä¸ªèµ„æºçš„å®Œæ•´æµç¨‹"""
        self.logger.info(f"å¼€å§‹å¤„ç†èµ„æº: {resource_info.filename}")

        try:
            # æ­¥éª¤1: ä¸‹è½½æ–‡ä»¶
            if not await self._download_resource(resource_info):
                return False

            # æ­¥éª¤2: ç”ŸæˆAIå†…å®¹
            if not await self._generate_content(resource_info):
                return False

            # æ­¥éª¤3: æœç´¢å’Œä¸‹è½½ç›¸å…³å›¾ç‰‡
            if not await self._process_images(resource_info):
                return False

            # æ­¥éª¤4: ä¸Šä¼ åˆ°ä»˜è´¹ä¸‹è½½å¹³å°
            if not await self._upload_to_hosting(resource_info):
                return False

            # æ­¥éª¤5: ä¿å­˜åˆ°æ•°æ®åº“
            if not await self._save_to_database(resource_info):
                return False

            self.logger.info(f"èµ„æºå¤„ç†å®Œæˆ: {resource_info.filename}")
            return True

        except Exception as e:
            self.logger.error(f"å¤„ç†èµ„æºå¤±è´¥ {resource_info.filename}: {e}")
            return False

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            await self._cleanup(resource_info)

    async def _download_resource(self, resource_info: ResourceInfo) -> bool:
        """ä¸‹è½½èµ„æºæ–‡ä»¶"""
        self.logger.info(f"æ­¥éª¤1: ä¸‹è½½æ–‡ä»¶ {resource_info.filename}")

        try:
            # ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
            local_path = await self.baidu_client.download_file(
                resource_info.path,
                resource_info.filename,
                config.download.base_dir
            )

            if not local_path:
                self.logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {resource_info.filename}")
                return False

            resource_info.local_path = local_path
            self.logger.info(f"æ–‡ä»¶ä¸‹è½½å®Œæˆ: {local_path}")
            return True

        except Exception as e:
            self.logger.error(f"ä¸‹è½½æ–‡ä»¶å‡ºé”™ {resource_info.filename}: {e}")
            return False

    async def _generate_content(self, resource_info: ResourceInfo) -> bool:
        """ç”ŸæˆAIå†…å®¹"""
        self.logger.info(f"æ­¥éª¤2: ç”ŸæˆAIå†…å®¹ {resource_info.filename}")

        try:
            # æå–æ–‡ä»¶å…ƒæ•°æ®
            metadata = await self._extract_metadata(resource_info)

            # ç”Ÿæˆå†…å®¹
            content_data = await self.content_generator.generate_content(
                filename=resource_info.filename,
                file_type=resource_info.file_type,
                resource_type=resource_info.resource_type,
                metadata=metadata,
                local_path=resource_info.local_path
            )

            if not content_data:
                self.logger.error(f"ç”ŸæˆAIå†…å®¹å¤±è´¥: {resource_info.filename}")
                return False

            resource_info.content_data = content_data
            self.logger.info(f"AIå†…å®¹ç”Ÿæˆå®Œæˆ: {content_data.get('title_zh', '')}")
            return True

        except Exception as e:
            self.logger.error(f"ç”ŸæˆAIå†…å®¹å‡ºé”™ {resource_info.filename}: {e}")
            return False

    async def _extract_metadata(self, resource_info: ResourceInfo) -> Dict[str, Any]:
        """æå–æ–‡ä»¶å…ƒæ•°æ®"""
        metadata = {
            "filename": resource_info.filename,
            "size": resource_info.size,
            "file_type": resource_info.file_type,
            "resource_type": resource_info.resource_type,
            "modified_time": resource_info.modified_time.isoformat()
        }

        # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œæå–æ›´å¤šå…ƒæ•°æ®
        if resource_info.local_path and os.path.exists(resource_info.local_path):
            try:
                import magic
                file_path = Path(resource_info.local_path)

                # æ£€æµ‹æ–‡ä»¶MIMEç±»å‹
                mime_type = magic.from_file(str(file_path), mime=True)
                metadata["mime_type"] = mime_type

                # å¦‚æœæ˜¯å‹ç¼©æ–‡ä»¶ï¼Œåˆ—å‡ºå†…å®¹
                if resource_info.file_type in ['.zip', '.rar', '.7z', '.tar', '.gz']:
                    metadata["archive_contents"] = await self._list_archive_contents(file_path)

                # å¦‚æœæ˜¯UnityåŒ…ï¼Œæå–Unityä¿¡æ¯
                if resource_info.file_type in ['.unitypackage', '.unity']:
                    metadata["unity_info"] = await self._extract_unity_info(file_path)

            except Exception as e:
                self.logger.warning(f"æå–å…ƒæ•°æ®å¤±è´¥: {e}")

        return metadata

    async def _list_archive_contents(self, file_path: Path) -> List[str]:
        """åˆ—å‡ºå‹ç¼©æ–‡ä»¶å†…å®¹"""
        try:
            import patoolib
            temp_dir = Path(config.download.base_dir) / "temp_extract"
            temp_dir.mkdir(exist_ok=True)

            # è§£å‹æ–‡ä»¶
            patoolib.extract_archive(str(file_path), outdir=str(temp_dir))

            # è·å–æ–‡ä»¶åˆ—è¡¨
            contents = []
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    rel_path = os.path.relpath(os.path.join(root, file), temp_dir)
                    contents.append(rel_path)

            # æ¸…ç†ä¸´æ—¶ç›®å½•
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)

            return contents[:50]  # è¿”å›å‰50ä¸ªæ–‡ä»¶

        except Exception as e:
            self.logger.warning(f"è§£å‹æ–‡ä»¶å¤±è´¥: {e}")
            return []

    async def _extract_unity_info(self, file_path: Path) -> Dict[str, Any]:
        """æå–UnityåŒ…ä¿¡æ¯"""
        # è¿™é‡Œå¯ä»¥å®ç°UnityåŒ…çš„è¯¦ç»†è§£æ
        # æš‚æ—¶è¿”å›åŸºæœ¬ä¿¡æ¯
        return {
            "package_type": "unitypackage",
            "unity_version": "unknown",
            "assets_count": 0
        }

    async def _process_images(self, resource_info: ResourceInfo) -> bool:
        """å¤„ç†ç›¸å…³å›¾ç‰‡"""
        self.logger.info(f"æ­¥éª¤3: æœç´¢å’Œä¸‹è½½ç›¸å…³å›¾ç‰‡ {resource_info.filename}")

        try:
            if not resource_info.content_data:
                self.logger.error("æ²¡æœ‰å†…å®¹æ•°æ®ï¼Œæ— æ³•æœç´¢å›¾ç‰‡")
                return False

            # æœç´¢å›¾ç‰‡
            images = await self.image_manager.search_and_download_images(
                title=resource_info.content_data.get('title_zh', ''),
                description=resource_info.content_data.get('description', ''),
                tags=resource_info.content_data.get('tags', []),
                resource_type=resource_info.resource_type,
                max_images=config.image.images_per_resource
            )

            if not images:
                self.logger.warning("æœªæ‰¾åˆ°ç›¸å…³å›¾ç‰‡")
                return True  # å›¾ç‰‡ä¸æ˜¯å¿…éœ€çš„

            # ä¸Šä¼ å›¾ç‰‡åˆ°Cloudflare R2
            uploaded_images = []
            for image_path in images:
                image_url = await self.r2_manager.upload_file(
                    file_path=image_path,
                    key=f"images/{resource_info.resource_type}/{Path(image_path).name}"
                )
                if image_url:
                    uploaded_images.append(image_url)

            resource_info.images = uploaded_images
            self.logger.info(f"å›¾ç‰‡å¤„ç†å®Œæˆï¼Œä¸Šä¼ äº† {len(uploaded_images)} å¼ å›¾ç‰‡")
            return True

        except Exception as e:
            self.logger.error(f"å¤„ç†å›¾ç‰‡å‡ºé”™ {resource_info.filename}: {e}")
            return False

    async def _upload_to_hosting(self, resource_info: ResourceInfo) -> bool:
        """ä¸Šä¼ åˆ°ä»˜è´¹ä¸‹è½½å¹³å°"""
        self.logger.info(f"æ­¥éª¤4: ä¸Šä¼ åˆ°ä»˜è´¹ä¸‹è½½å¹³å° {resource_info.filename}")

        try:
            if not resource_info.local_path or not os.path.exists(resource_info.local_path):
                self.logger.error("æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ä¸Šä¼ ")
                return False

            # ä¸Šä¼ åˆ°å„ä¸ªå¹³å°
            hosting_links = []

            # Rapidgator
            if config.hosting.rapidgator_api_key:
                rapidgator_link = await self.hosting_manager.upload_to_rapidgator(
                    resource_info.local_path,
                    resource_info.filename
                )
                if rapidgator_link:
                    hosting_links.append({
                        "platform": "rapidgator",
                        "url": rapidgator_link,
                        "name": "Rapidgator"
                    })

            # Turbobit
            if config.hosting.turbobit_api_key:
                turbobit_link = await self.hosting_manager.upload_to_turbobit(
                    resource_info.local_path,
                    resource_info.filename
                )
                if turbobit_link:
                    hosting_links.append({
                        "platform": "turbobit",
                        "url": turbobit_link,
                        "name": "Turbobit"
                    })

            # FileCat
            if config.hosting.filecat_api_key:
                filecat_link = await self.hosting_manager.upload_to_filecat(
                    resource_info.local_path,
                    resource_info.filename
                )
                if filecat_link:
                    hosting_links.append({
                        "platform": "filecat",
                        "url": filecat_link,
                        "name": "FileCat"
                    })

            resource_info.hosting_links = hosting_links
            self.logger.info(f"æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼ŒæˆåŠŸä¸Šä¼ åˆ° {len(hosting_links)} ä¸ªå¹³å°")
            return len(hosting_links) > 0

        except Exception as e:
            self.logger.error(f"ä¸Šä¼ åˆ°ä»˜è´¹å¹³å°å‡ºé”™ {resource_info.filename}: {e}")
            return False

    async def _save_to_database(self, resource_info: ResourceInfo) -> bool:
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        self.logger.info(f"æ­¥éª¤5: ä¿å­˜åˆ°æ•°æ®åº“ {resource_info.filename}")

        try:
            # å‡†å¤‡æ•°æ®åº“æ•°æ®
            db_data = {
                "title": resource_info.content_data.get('title_zh', ''),
                "title_en": resource_info.content_data.get('title_en', ''),
                "description": resource_info.content_data.get('description', ''),
                "meta_description": resource_info.content_data.get('meta_description', ''),
                "resource_type": resource_info.resource_type,
                "file_size": resource_info.size,
                "file_format": resource_info.file_type,
                "download_links": json.dumps(resource_info.hosting_links),
                "image_urls": json.dumps(resource_info.images),
                "tags": json.dumps(resource_info.content_data.get('tags', [])),
                "status": "published",
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }

            # ä¿å­˜åˆ°æ•°æ®åº“
            resource_id = await self.db.create_resource(db_data)

            if resource_id:
                self.logger.info(f"èµ„æºå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼ŒID: {resource_id}")
                return True
            else:
                self.logger.error("ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥")
                return False

        except Exception as e:
            self.logger.error(f"ä¿å­˜åˆ°æ•°æ®åº“å‡ºé”™ {resource_info.filename}: {e}")
            return False

    async def _cleanup(self, resource_info: ResourceInfo):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            # æ¸…ç†ä¸‹è½½çš„æ–‡ä»¶
            if resource_info.local_path and os.path.exists(resource_info.local_path):
                os.remove(resource_info.local_path)
                self.logger.debug(f"å·²æ¸…ç†ä¸‹è½½æ–‡ä»¶: {resource_info.local_path}")

            # æ¸…ç†å›¾ç‰‡æ–‡ä»¶
            for image_path in resource_info.images:
                if image_path.startswith(config.image.download_dir):
                    if os.path.exists(image_path):
                        os.remove(image_path)
                        self.logger.debug(f"å·²æ¸…ç†å›¾ç‰‡æ–‡ä»¶: {image_path}")

        except Exception as e:
            self.logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


class AutomationOrchestrator:
    """è‡ªåŠ¨åŒ–ç¼–æ’å™¨"""

    def __init__(self):
        self.logger = setup_logger("AutomationOrchestrator")
        self.processor = ResourceProcessor()
        self.baidu_client = BaiduPanClient()

    async def run_automation(self, target_path: str = None, limit: int = 1):
        """è¿è¡Œè‡ªåŠ¨åŒ–æµç¨‹"""
        self.logger.info("=== å¼€å§‹ ResLibs ç™¾åº¦ç½‘ç›˜è‡ªåŠ¨åŒ–æµç¨‹ ===")

        try:
            # è·å–ç›®æ ‡è·¯å¾„
            path = target_path or config.baidu_pan.path

            # è·å–æ–‡ä»¶åˆ—è¡¨
            self.logger.info(f"è·å–æ–‡ä»¶åˆ—è¡¨: {path}")
            files = await self.baidu_client.list_files(path)

            if not files:
                self.logger.warning("æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
                return

            self.logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†å‰ {limit} ä¸ª")

            # å¤„ç†æ–‡ä»¶
            processed_count = 0
            for i, file_info in enumerate(files[:limit]):
                self.logger.info(f"\n--- å¤„ç†ç¬¬ {i+1}/{min(limit, len(files))} ä¸ªæ–‡ä»¶ ---")

                # åˆ›å»ºèµ„æºä¿¡æ¯å¯¹è±¡
                resource_info = ResourceInfo(
                    path=file_info['path'],
                    filename=file_info['filename'],
                    size=file_info['size'],
                    modified_time=file_info['modified_time'],
                    file_type=file_info['file_type'],
                    resource_type=file_info['resource_type']
                )

                # å¤„ç†èµ„æº
                success = await self.processor.process_single_resource(resource_info)

                if success:
                    processed_count += 1
                    self.logger.info(f"âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ: {resource_info.filename}")
                else:
                    self.logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {resource_info.filename}")

                # æ­¥éª¤é—´æš‚åœ
                if i < min(limit, len(files)) - 1:
                    self.logger.info(f"æš‚åœ {config.system.pause_between_steps} ç§’...")
                    await asyncio.sleep(config.system.pause_between_steps)

            self.logger.info(f"\n=== è‡ªåŠ¨åŒ–æµç¨‹å®Œæˆ ===")
            self.logger.info(f"æ€»å…±å¤„ç†: {min(limit, len(files))} ä¸ªæ–‡ä»¶")
            self.logger.info(f"æˆåŠŸå¤„ç†: {processed_count} ä¸ªæ–‡ä»¶")
            self.logger.info(f"å¤±è´¥å¤„ç†: {min(limit, len(files)) - processed_count} ä¸ªæ–‡ä»¶")

        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨åŒ–æµç¨‹å‡ºé”™: {e}")
            raise


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ResLibs ç™¾åº¦ç½‘ç›˜è‡ªåŠ¨åŒ–è„šæœ¬")
    parser.add_argument("--path", help="ç™¾åº¦ç½‘ç›˜ç›®æ ‡è·¯å¾„")
    parser.add_argument("--limit", type=int, default=1, help="å¤„ç†æ–‡ä»¶æ•°é‡é™åˆ¶")
    parser.add_argument("--dry-run", action="store_true", help="è¯•è¿è¡Œæ¨¡å¼")
    parser.add_argument("--config", action="store_true", help="æ˜¾ç¤ºé…ç½®ä¿¡æ¯")

    args = parser.parse_args()

    # æ˜¾ç¤ºé…ç½®
    if args.config:
        config.print_config_summary()
        return

    # è®¾ç½®è¯•è¿è¡Œæ¨¡å¼
    if args.dry_run:
        config.system.dry_run = True
        print("ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šä¸ä¼šå®é™…ä¸‹è½½å’Œä¸Šä¼ æ–‡ä»¶")

    try:
        # åˆå§‹åŒ–ç¼–æ’å™¨
        orchestrator = AutomationOrchestrator()

        # è¿è¡Œè‡ªåŠ¨åŒ–æµç¨‹
        await orchestrator.run_automation(
            target_path=args.path,
            limit=args.limit
        )

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(".env.automation"):
        print("âŒ æœªæ‰¾åˆ° .env.automation é…ç½®æ–‡ä»¶")
        print("è¯·å¤åˆ¶ .env.automation.example ä¸º .env.automation å¹¶å¡«å…¥é…ç½®")
        sys.exit(1)

    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())